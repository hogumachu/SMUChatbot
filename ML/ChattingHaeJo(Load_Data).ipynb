{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers, losses, metrics\n",
    "from keras import preprocessing\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAG Word\n",
    "PAD = \"<PADDING>\" \n",
    "STA = \"<START>\"  \n",
    "END = \"<END>\" \n",
    "OOV = \"<OOV>\"\n",
    "\n",
    "# Tag Index\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "OOV_INDEX = 3\n",
    "\n",
    "# Data Type\n",
    "ENCODER_INPUT  = 0\n",
    "DECODER_INPUT  = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "# MAXiMUM Sequnce\n",
    "max_sequences = 30\n",
    "\n",
    "# Embedding Vector Dimension\n",
    "embedding_dim = 100\n",
    "\n",
    "# LSTM Hidden Layer Dimension\n",
    "lstm_hidden_dim = 128\n",
    "\n",
    "# Filter\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.load(\"words.npy\")\n",
    "word_to_index = np.load(\"word_to_index.npy\", allow_pickle=True)\n",
    "index_to_word = np.load(\"index_to_word.npy\", allow_pickle=True)\n",
    "word_to_index = dict(enumerate(word_to_index.flatten()))[0]\n",
    "index_to_word = dict(enumerate(index_to_word.flatten()))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PADDING>': 0,\n",
       " '<START>': 1,\n",
       " '<END>': 2,\n",
       " '<OOV>': 3,\n",
       " 'IOT': 4,\n",
       " 'iot': 5,\n",
       " 'office': 6,\n",
       " 'professor': 7,\n",
       " '가': 8,\n",
       " '가나': 9,\n",
       " '가는': 10,\n",
       " '가복': 11,\n",
       " '가야해': 12,\n",
       " '가요': 13,\n",
       " '가족': 14,\n",
       " '가족복지학과': 15,\n",
       " '갈': 16,\n",
       " '감': 17,\n",
       " '강': 18,\n",
       " '강성': 19,\n",
       " '개발': 20,\n",
       " '건강': 21,\n",
       " '게임': 22,\n",
       " '게임전공': 23,\n",
       " '게임학': 24,\n",
       " '겜': 25,\n",
       " '경': 26,\n",
       " '경과': 27,\n",
       " '경영': 28,\n",
       " '경영학': 29,\n",
       " '경영학부': 30,\n",
       " '경제': 31,\n",
       " '경제금융학부': 32,\n",
       " '경제학': 33,\n",
       " '계': 34,\n",
       " '계셔': 35,\n",
       " '계신지': 36,\n",
       " '계심': 37,\n",
       " '고': 38,\n",
       " '공': 39,\n",
       " '공간': 40,\n",
       " '공간환경학부': 41,\n",
       " '공과': 42,\n",
       " '공임': 43,\n",
       " '공학': 44,\n",
       " '공학교육혁신센터': 45,\n",
       " '공환': 46,\n",
       " '과': 47,\n",
       " '과사': 48,\n",
       " '관리': 49,\n",
       " '관리팀': 50,\n",
       " '교수': 51,\n",
       " '교원': 52,\n",
       " '교원인사': 53,\n",
       " '교원인사팀': 54,\n",
       " '교육': 55,\n",
       " '교육학': 56,\n",
       " '교육학과': 57,\n",
       " '교직': 58,\n",
       " '교직지원센터': 59,\n",
       " '교학': 60,\n",
       " '교학팀': 61,\n",
       " '국': 62,\n",
       " '국가': 63,\n",
       " '국가안보학과': 64,\n",
       " '국교': 65,\n",
       " '국안': 66,\n",
       " '국어': 67,\n",
       " '국어교육': 68,\n",
       " '국어교육과': 69,\n",
       " '국제': 70,\n",
       " '국제언어문화교육원': 71,\n",
       " '국제학생지원팀': 72,\n",
       " '권': 73,\n",
       " '귀': 74,\n",
       " '귀지': 75,\n",
       " '글': 76,\n",
       " '글경': 77,\n",
       " '글로벌': 78,\n",
       " '글로벌경영학과': 79,\n",
       " '글로벌랭귀지센터': 80,\n",
       " '금': 81,\n",
       " '금융': 82,\n",
       " '기기': 83,\n",
       " '기초': 84,\n",
       " '기초교육센터': 85,\n",
       " '기획': 86,\n",
       " '기획예산팀': 87,\n",
       " '김': 88,\n",
       " '김경일': 89,\n",
       " '김동아': 90,\n",
       " '김미숙': 91,\n",
       " '김유천': 92,\n",
       " '김정임': 93,\n",
       " '김지영': 94,\n",
       " '김한식': 95,\n",
       " '까요': 96,\n",
       " '께': 97,\n",
       " '나': 98,\n",
       " '능력': 99,\n",
       " '님': 100,\n",
       " '단': 101,\n",
       " '담소': 102,\n",
       " '대대': 103,\n",
       " '대체': 104,\n",
       " '대학': 105,\n",
       " '대학일자리센터': 106,\n",
       " '도대체': 107,\n",
       " '돼': 108,\n",
       " '되': 109,\n",
       " '되나요': 110,\n",
       " '됩니까': 111,\n",
       " '디자인': 112,\n",
       " '란': 113,\n",
       " '랭': 114,\n",
       " '로': 115,\n",
       " '를': 116,\n",
       " '만나고': 117,\n",
       " '만나려면': 118,\n",
       " '머': 119,\n",
       " '머임': 120,\n",
       " '메이저': 121,\n",
       " '메일': 122,\n",
       " '멜': 123,\n",
       " '면': 124,\n",
       " '명': 125,\n",
       " '무슨': 126,\n",
       " '무예': 127,\n",
       " '무용': 128,\n",
       " '무용예술전공': 129,\n",
       " '묵': 130,\n",
       " '문': 131,\n",
       " '문자': 132,\n",
       " '문정': 133,\n",
       " '문헌': 134,\n",
       " '문헌정보': 135,\n",
       " '문헌정보학': 136,\n",
       " '문헌정보학전공': 137,\n",
       " '문화': 138,\n",
       " '뭐': 139,\n",
       " '뭐삼': 140,\n",
       " '뭐임': 141,\n",
       " '뭔': 142,\n",
       " '미': 143,\n",
       " '바': 144,\n",
       " '박물관': 145,\n",
       " '박재근': 146,\n",
       " '방경': 147,\n",
       " '방법': 148,\n",
       " '방송': 149,\n",
       " '방송국': 150,\n",
       " '백': 151,\n",
       " '번호': 152,\n",
       " '법': 153,\n",
       " '법좀': 154,\n",
       " '보건': 155,\n",
       " '보건건강관리센터': 156,\n",
       " '복지': 157,\n",
       " '봐': 158,\n",
       " '봐라': 159,\n",
       " '봬려': 160,\n",
       " '뵈려면': 161,\n",
       " '사': 162,\n",
       " '사무실': 163,\n",
       " '사업': 164,\n",
       " '산학': 165,\n",
       " '산학협력지원팀': 166,\n",
       " '삼실': 167,\n",
       " '상': 168,\n",
       " '상담': 169,\n",
       " '상명아트센터': 170,\n",
       " '생': 171,\n",
       " '생공': 172,\n",
       " '생명': 173,\n",
       " '생명공학': 174,\n",
       " '생명공학전공': 175,\n",
       " '생예': 176,\n",
       " '생활': 177,\n",
       " '생활관': 178,\n",
       " '생활예술전공': 179,\n",
       " '서': 180,\n",
       " '서정': 181,\n",
       " '석': 182,\n",
       " '선희': 183,\n",
       " '세용': 184,\n",
       " '센터': 185,\n",
       " '소속': 186,\n",
       " '소통': 187,\n",
       " '소프트웨어': 188,\n",
       " '소프트웨어융합교육센터': 189,\n",
       " '쇼': 190,\n",
       " '수': 191,\n",
       " '수교': 192,\n",
       " '수학': 193,\n",
       " '수학교육과': 194,\n",
       " '순정': 195,\n",
       " '술': 196,\n",
       " '스건': 197,\n",
       " '스포츠': 198,\n",
       " '스포츠건강관리전공': 199,\n",
       " '식영': 200,\n",
       " '식품': 201,\n",
       " '식품영양학전공': 202,\n",
       " '신': 203,\n",
       " '신문': 204,\n",
       " '신문방송국': 205,\n",
       " '신방': 206,\n",
       " '신소재': 207,\n",
       " '신지': 208,\n",
       " '십': 209,\n",
       " '싶어': 210,\n",
       " '싶은데': 211,\n",
       " '아': 212,\n",
       " '아니': 213,\n",
       " '아셈': 214,\n",
       " '아시나요': 215,\n",
       " '아트': 216,\n",
       " '안과': 217,\n",
       " '안보': 218,\n",
       " '알': 219,\n",
       " '알려주랑': 220,\n",
       " '알려주세요': 221,\n",
       " '알려주십': 222,\n",
       " '알려줄': 223,\n",
       " '알려줄래': 224,\n",
       " '알려줘': 225,\n",
       " '알려줭': 226,\n",
       " '앎': 227,\n",
       " '애니': 228,\n",
       " '애니메이션': 229,\n",
       " '애니메이션전공': 230,\n",
       " '야': 231,\n",
       " '양동국': 232,\n",
       " '어디': 233,\n",
       " '어딘': 234,\n",
       " '어딘가': 235,\n",
       " '어딜': 236,\n",
       " '어딨음': 237,\n",
       " '어떤': 238,\n",
       " '어떻게': 239,\n",
       " '어뜨케': 240,\n",
       " '어문': 241,\n",
       " '어케': 242,\n",
       " '어케감': 243,\n",
       " '언': 244,\n",
       " '에': 245,\n",
       " '에너지': 246,\n",
       " '에너지공학': 247,\n",
       " '역사': 248,\n",
       " '역사콘텐츠전공': 249,\n",
       " '역콘': 250,\n",
       " '연락': 251,\n",
       " '연락처': 252,\n",
       " '염': 253,\n",
       " '영교': 254,\n",
       " '영양': 255,\n",
       " '영양학': 256,\n",
       " '영어': 257,\n",
       " '영어교육과': 258,\n",
       " '예비군': 259,\n",
       " '예비군대대': 260,\n",
       " '예산': 261,\n",
       " '예술': 262,\n",
       " '외국인': 263,\n",
       " '외국인유학생상담센터': 264,\n",
       " '요': 265,\n",
       " '욤': 266,\n",
       " '용': 267,\n",
       " '우편': 268,\n",
       " '우편취급국': 269,\n",
       " '운영': 270,\n",
       " '원': 271,\n",
       " '위치': 272,\n",
       " '유동관': 273,\n",
       " '유부': 274,\n",
       " '유학생': 275,\n",
       " '유현': 276,\n",
       " '윤': 277,\n",
       " '윤진': 278,\n",
       " '융경': 279,\n",
       " '융합': 280,\n",
       " '융합경영학과': 281,\n",
       " '은': 282,\n",
       " '을': 283,\n",
       " '음악': 284,\n",
       " '음악학부': 285,\n",
       " '의류': 286,\n",
       " '의류학전공': 287,\n",
       " '의사': 288,\n",
       " '의사소통': 289,\n",
       " '의사소통능력개발센터': 290,\n",
       " '이': 291,\n",
       " '이메일': 292,\n",
       " '이야': 293,\n",
       " '이영학': 294,\n",
       " '이정학': 295,\n",
       " '이화원': 296,\n",
       " '인가': 297,\n",
       " '인가요': 298,\n",
       " '인권': 299,\n",
       " '인권상': 300,\n",
       " '인권상담소': 301,\n",
       " '인사': 302,\n",
       " '인숙': 303,\n",
       " '인지': 304,\n",
       " '일': 305,\n",
       " '일자리': 306,\n",
       " '임': 307,\n",
       " '입학': 308,\n",
       " '입학처': 309,\n",
       " '있나요': 310,\n",
       " '있는': 311,\n",
       " '있는지': 312,\n",
       " '있을까': 313,\n",
       " '장소': 314,\n",
       " '장애': 315,\n",
       " '장애학생지원센터': 316,\n",
       " '장혜숙': 317,\n",
       " '재': 318,\n",
       " '재무': 319,\n",
       " '재무회계': 320,\n",
       " '재무회계팀': 321,\n",
       " '재산': 322,\n",
       " '전': 323,\n",
       " '전공': 324,\n",
       " '전기': 325,\n",
       " '전기공학': 326,\n",
       " '전기공학과': 327,\n",
       " '전략': 328,\n",
       " '전략평가팀': 329,\n",
       " '전번': 330,\n",
       " '전화번호': 331,\n",
       " '전화해야': 332,\n",
       " '전화해야해': 333,\n",
       " '점': 334,\n",
       " '정보': 335,\n",
       " '정보공학': 336,\n",
       " '정보통': 337,\n",
       " '정보통신팀': 338,\n",
       " '정유': 339,\n",
       " '제민': 340,\n",
       " '조': 341,\n",
       " '조예': 342,\n",
       " '조형': 343,\n",
       " '조형예술': 344,\n",
       " '조형예술전공': 345,\n",
       " '좀': 346,\n",
       " '종범': 347,\n",
       " '주': 348,\n",
       " '주소': 349,\n",
       " '주진오': 350,\n",
       " '준현': 351,\n",
       " '중앙': 352,\n",
       " '중앙기기센터': 353,\n",
       " '지': 354,\n",
       " '지능': 355,\n",
       " '지능IOT융합전공': 356,\n",
       " '지원': 357,\n",
       " '지적': 358,\n",
       " '지적재산': 359,\n",
       " '지적재산권': 360,\n",
       " '지적재산권전공': 361,\n",
       " '진로': 362,\n",
       " '진로지원팀': 363,\n",
       " '쯤': 364,\n",
       " '창업': 365,\n",
       " '창업지원센터(창업지원팀)': 366,\n",
       " '총무': 367,\n",
       " '총무인사팀': 368,\n",
       " '최상': 369,\n",
       " '최연식': 370,\n",
       " '최종': 371,\n",
       " '취급': 372,\n",
       " '취업': 373,\n",
       " '취업지원팀': 374,\n",
       " '캠퍼스': 375,\n",
       " '캠퍼스타운사업단': 376,\n",
       " '커뮤': 377,\n",
       " '커뮤니케이션': 378,\n",
       " '커뮤니케이션팀': 379,\n",
       " '컴': 380,\n",
       " '컴공': 381,\n",
       " '컴터': 382,\n",
       " '컴퓨터': 383,\n",
       " '컴퓨터과학': 384,\n",
       " '컴퓨터과학과': 385,\n",
       " '콘텐츠': 386,\n",
       " '타운': 387,\n",
       " '테크': 388,\n",
       " '통신': 389,\n",
       " '팀': 390,\n",
       " '평가': 391,\n",
       " '평생': 392,\n",
       " '평생교육': 393,\n",
       " '평생교육원교학팀': 394,\n",
       " '폰번': 395,\n",
       " '핀': 396,\n",
       " '핀테크전공': 397,\n",
       " '하고': 398,\n",
       " '하셨나요': 399,\n",
       " '하셨어': 400,\n",
       " '학': 401,\n",
       " '학과': 402,\n",
       " '학부': 403,\n",
       " '학사': 404,\n",
       " '학사운영팀': 405,\n",
       " '학생': 406,\n",
       " '학생복': 407,\n",
       " '학생복지팀': 408,\n",
       " '학생상담센터': 409,\n",
       " '학생생활관': 410,\n",
       " '학술': 411,\n",
       " '학술정보지원팀': 412,\n",
       " '한': 413,\n",
       " '한문': 414,\n",
       " '한일': 415,\n",
       " '한일문화콘텐츠과': 416,\n",
       " '한콘': 417,\n",
       " '한테': 418,\n",
       " '할': 419,\n",
       " '함': 420,\n",
       " '해': 421,\n",
       " '해야': 422,\n",
       " '혁신': 423,\n",
       " '협력': 424,\n",
       " '화': 425,\n",
       " '화공': 426,\n",
       " '화공신소재전공': 427,\n",
       " '화신': 428,\n",
       " '화학': 429,\n",
       " '화학에너지전공': 430,\n",
       " '환': 431,\n",
       " '환경': 432,\n",
       " '환경학': 433,\n",
       " '황종': 434,\n",
       " '회계': 435,\n",
       " '효': 436,\n",
       " '휴먼': 437,\n",
       " '휴먼지능정보공학과': 438,\n",
       " '휴지': 439}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs = model.layers[2](encoder_inputs)\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[4](encoder_outputs)\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(lstm_hidden_dim,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(lstm_hidden_dim,), name='input_4')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs = model.layers[3](decoder_inputs)\n",
    "decoder_lstm = model.layers[5]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_outputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[6]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    \n",
    "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
    "    states = encoder_model.predict(input_seq)\n",
    "    #states = encoder.predict(input_seq)\n",
    "    # 목표 시퀀스 초기화\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
    "    target_seq[0, 0] = STA_INDEX\n",
    "    \n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 타임 스텝 반복\n",
    "    while 1:\n",
    "        decoder_outputs, state_h, state_c = decoder_model.predict([target_seq] + states)\n",
    "        \n",
    "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "        index = np.argmax(decoder_outputs[0, 0, :])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 검사\n",
    "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
    "            break\n",
    "\n",
    "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = index\n",
    "        \n",
    "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    sentences = pos_tag(sentences)\n",
    "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
    "    \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(sentences):\n",
    "    \n",
    "    # KoNLPy 형태소분석기 설정\n",
    "    tagger = Okt()\n",
    "    \n",
    "    # 문장 품사 변수 초기화\n",
    "    sentences_pos = []\n",
    "    \n",
    "    # 모든 문장 반복\n",
    "    for sentence in sentences:\n",
    "        # 특수기호 제거\n",
    "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
    "        \n",
    "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
    "        sentence = \" \".join(tagger.morphs(sentence))\n",
    "        sentences_pos.append(sentence)\n",
    "        \n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == END_INDEX:\n",
    "            # 종료 인덱스면 중지\n",
    "            break;\n",
    "        if vocabulary.get(index) is not None:\n",
    "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
    "            sentence += vocabulary[index]\n",
    "        else:\n",
    "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
    "            sentence.extend([vocabulary[OOV_INDEX]])\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "def convert_text_to_index(sentences, vocabulary, type): \n",
    "    \n",
    "    sentences_index = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence_index = []\n",
    "        \n",
    "        if type == DECODER_INPUT:\n",
    "            sentence_index.extend([vocabulary[STA]])\n",
    "        \n",
    "        # 문장의 단어들을 띄어쓰기로 분리\n",
    "        for word in sentence.split():\n",
    "            if vocabulary.get(word) is not None:\n",
    "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "        # 최대 길이 검사\n",
    "        if type == DECODER_TARGET:\n",
    "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
    "            if len(sentence_index) >= max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
    "            else:\n",
    "                sentence_index += [vocabulary[END]]\n",
    "        else:\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences]\n",
    "            \n",
    "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
    "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "        \n",
    "        # 문장의 인덱스 배열을 추가\n",
    "        sentences_index.append(sentence_index)\n",
    "\n",
    "    return np.asarray(sentences_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,  51, 100, 252,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = make_predict_input('한혁수 교수님 연락처')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professor 연락처 '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[384,  47, 272,   8, 233, 231,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = make_predict_input('컴퓨터과학과 위치가 어디야')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'office 컴퓨터과학과 위치 '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴공 연락처\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'office 컴퓨터과학과 연락처 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(make_predict_input(input()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    44000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    44000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  117248      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 440)    56760       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 379,256\n",
      "Trainable params: 379,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
